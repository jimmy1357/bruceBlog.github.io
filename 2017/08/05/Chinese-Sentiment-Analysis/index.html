<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Chinese Sentiment Analysis | July7</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Sentiment analysis (sometimes known as opinion mining or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identi">
<meta name="keywords" content="Sentiment Analysis">
<meta property="og:type" content="article">
<meta property="og:title" content="Chinese Sentiment Analysis">
<meta property="og:url" content="http://july7.me/2017/08/05/Chinese-Sentiment-Analysis/index.html">
<meta property="og:site_name" content="July7">
<meta property="og:description" content="Sentiment analysis (sometimes known as opinion mining or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identi">
<meta property="og:image" content="http://july7.me/images/pasted-35.png">
<meta property="og:updated_time" content="2017-08-19T14:46:24.162Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chinese Sentiment Analysis">
<meta name="twitter:description" content="Sentiment analysis (sometimes known as opinion mining or emotion AI) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identi">
<meta name="twitter:image" content="http://july7.me/images/pasted-35.png">
  
    <link rel="alternative" href="/atom.xml" title="July7" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  
      <link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">
  
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet" />
  <script>
      var yiliaConfig = {
          rootUrl: '/',
          fancybox: true,
          animate: true,
          isHome: false,
          isPost: true,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            
            <img lazy-src="/img/head.jpg" class="js-avatar">
            
        </a>

        <hgroup>
          <h1 class="header-author"><a href="/" title="Hi Mate">Chen</a></h1>
        </hgroup>

        
        <p class="header-subtitle">The very beginning mind itself is the most accomplished mind of true enlightenment.</p>
        
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>Menu</li>
                        <li>Tags</li>
                        
                        <li>Links</li>
                        
                        
                        <li>About</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">Home</a></li>
                        
                            <li><a href="/works">Works</a></li>
                        
                            <li><a href="/Essays">Essays</a></li>
                        
                            <li><a href="/about">About</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl mail" target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=1efi4_Pt5_Tl4JWkpPu2urg" title="mail">mail</a>
                            
                                <a class="fl github" target="_blank" href="https://github.com/july7cji" title="github">github</a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/CTR/" style="font-size: 10px;">CTR</a> <a href="/tags/Feature-Engineering/" style="font-size: 20px;">Feature Engineering</a> <a href="/tags/Sentiment-Analysis/" style="font-size: 10px;">Sentiment Analysis</a> <a href="/tags/hexo/" style="font-size: 20px;">hexo</a>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a target="_blank" class="main-nav-link switch-friends-link" href="https://jimmy1357.github.io/bruceBlog.github.io/">name</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">A song, a photo, a trip, and a soul mate.</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="Me">Chen</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/head.jpg" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="Me">Chen</a></h1>
            </hgroup>
            
            <p class="header-subtitle">The very beginning mind itself is the most accomplished mind of true enlightenment.</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">Home</a></li>
                
                    <li><a href="/works">Works</a></li>
                
                    <li><a href="/Essays">Essays</a></li>
                
                    <li><a href="/about">About</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="mail" target="_blank" href="http://mail.qq.com/cgi-bin/qm_share?t=qm_mailme&email=1efi4_Pt5_Tl4JWkpPu2urg" title="mail">mail</a>
                    
                        <a class="github" target="_blank" href="https://github.com/july7cji" title="github">github</a>
                    
                </div>
            </nav>
        </header>                
    </div>
</nav>
      <div class="body-wrap"><article id="post-Chinese-Sentiment-Analysis" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2017/08/05/Chinese-Sentiment-Analysis/" class="article-date">
      <time datetime="2017-08-05T10:24:00.000Z" itemprop="datePublished">2017-08-05</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Chinese Sentiment Analysis
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Sentiment-Analysis/">Sentiment Analysis</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p><strong>Sentiment analysis</strong> (sometimes known as <strong>opinion mining</strong> or <strong>emotion AI</strong>) refers to the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine.</p>
<a id="more"></a>
<div align="right"><br>–  from <a href="https://en.wikipedia.org/wiki/Sentiment_analysis" target="_blank" rel="external"><strong>Wikipedia</strong></a><br></div>

<h1 id="1-Corpus"><a href="#1-Corpus" class="headerlink" title="1.Corpus"></a>1.Corpus</h1><p><em>Corpus 1</em>: <a href="http://www.nlpir.org/?action-viewnews-itemid-77" target="_blank" rel="external">情感挖掘的酒店评论语料</a></p>
<p><em>Corpus 2</em>: <a href="http://tcci.ccf.org.cn/conference/2012/pages/page10_dl.html" target="_blank" rel="external">2012年CCF自然语言处理与中文计算会议：中文微博情感分析测评数据</a></p>
<p><em>Corpus 3</em>: <a href="http://www.datatang.com/data/14614" target="_blank" rel="external">中文情感挖掘语料-ChnSentiCorp</a></p>
<p><em>Corpus 4</em>: <a href="http://www.datatang.com/data/13539" target="_blank" rel="external">豆瓣网影评情感测试语料</a></p>
<p><em>Corpus 5</em>: <a href="http://alt.qcri.org/semeval2016/task5/index.php?id=data-and-tools" target="_blank" rel="external">SemEval-2016(包含移动手机，数码产品评论数据，分为训练数据和测试数据)</a></p>
<p>笔者使用的是Corpus 5.</p>
<h1 id="2-Data-preprocessing"><a href="#2-Data-preprocessing" class="headerlink" title="2. Data preprocessing"></a>2. Data preprocessing</h1><p>数据预处理: 主要包括读取格式化数据,文本分词等.</p>
<p>首先,将xml语料转换成带标记的文本,输出到文件中(这里省略输出部分的代码,只做解析工作). </p>
<p><strong><em>血与泪的教训: 解析xml等文件时,字段名一定不要手输</em></strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">decodeXML</span><span class="params">(url)</span>:</span></div><div class="line">    dom = xmlparser.parse(url)</div><div class="line">    root = dom.documentElement</div><div class="line"></div><div class="line">    pos = []</div><div class="line">    neg = []</div><div class="line"></div><div class="line">    sentencelists = root.getElementsByTagName(<span class="string">"sentences"</span>)</div><div class="line">    <span class="keyword">for</span> sentencelist <span class="keyword">in</span> sentencelists:</div><div class="line">        sentences = sentencelist.getElementsByTagName(<span class="string">"sentence"</span>)</div><div class="line">        <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences:</div><div class="line">            text = sentence.getElementsByTagName(<span class="string">"text"</span>)[<span class="number">0</span>].childNodes[<span class="number">0</span>].data</div><div class="line">            options = sentence.getElementsByTagName(<span class="string">"Opinions"</span>)</div><div class="line">            <span class="keyword">if</span> options:</div><div class="line">                option = options[<span class="number">0</span>].getElementsByTagName(<span class="string">"Opinion"</span>)</div><div class="line">                <span class="keyword">if</span> option[<span class="number">0</span>].hasAttribute(<span class="string">"polarity"</span>):</div><div class="line">                    polarity = option[<span class="number">0</span>].getAttribute(<span class="string">"polarity"</span>)</div><div class="line">                    <span class="keyword">if</span> polarity == <span class="string">"positive"</span>:</div><div class="line">                        label = <span class="number">1</span> </div><div class="line">                    <span class="keyword">elif</span> polarity == <span class="string">"negative"</span>:</div><div class="line">                        label = <span class="number">2</span> </div><div class="line">                    <span class="keyword">else</span>:</div><div class="line">                        <span class="keyword">print</span> <span class="string">"polarity error occured"</span></div><div class="line">                        <span class="keyword">continue</span></div><div class="line">                    line = str(label) + <span class="string">" "</span> + text</div><div class="line">                    <span class="comment">#print line</span></div><div class="line">                    <span class="keyword">if</span> label == <span class="number">1</span>:</div><div class="line">                        pos.append(line)</div><div class="line">                    <span class="keyword">else</span>:</div><div class="line">                        neg.append(line)</div><div class="line">    <span class="keyword">return</span> pos, neg</div></pre></td></tr></table></figure>
<p>由于语料中是讲一整条评论拆分成一个个句子,然后对句子分别做positive或negative标注的,而并不是每个句子都有情感倾向,因此有些句子是没有标注的(没有明显的倾向).<br><strong>笔者这里只提取了语料中的带标注部分,作为训练集和测试集.也就是说,笔者把它看做一个二分类问题</strong> 而在实际应用中, 需要斟酌到底是一个二分类问题,还是一个三分类问题.其分类效果也要视实际情况而定.</p>
<div align="center"><br><strong><em>一切脱离数据固有特性而谈论算法的行为,都是耍流氓.</em></strong><br></div><br><div align="right"><br>–  by Chen<br></div>

<p>之后, 进行分词,分词使用<a href="https://github.com/fxsjy/jieba" target="_blank" rel="external">jieba</a>. 这里笔者没有去停词,因为部分停词(例如语气词)对情感分类非常重要.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">segmenter</span><span class="params">(input_, output_, stopwordsPath=<span class="string">""</span>)</span>:</span></div><div class="line">    stopwords = []</div><div class="line">    <span class="keyword">if</span> stopwordsPath != <span class="string">""</span>: </div><div class="line">        <span class="keyword">with</span> open(stopwordsPath, <span class="string">'r'</span>)<span class="keyword">as</span> fin:</div><div class="line">            <span class="keyword">for</span> word <span class="keyword">in</span> fin:</div><div class="line">                word = word.strip()</div><div class="line">                stopwords.append(word)</div><div class="line">    <span class="keyword">with</span> open(input_, <span class="string">'r'</span>)<span class="keyword">as</span> fin, open(output_, <span class="string">'w'</span>)<span class="keyword">as</span> fout:</div><div class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> fin:</div><div class="line">            line = line.strip()</div><div class="line">            line = line.split(<span class="string">' '</span>, <span class="number">1</span>)</div><div class="line">            label = line[<span class="number">0</span>]</div><div class="line">            sentence = line[<span class="number">1</span>]</div><div class="line">            words = jieba.lcut(sentence)</div><div class="line">            <span class="keyword">if</span> stopwords: <span class="comment"># performance problem</span></div><div class="line">                words_ = [x <span class="keyword">for</span> x <span class="keyword">in</span> words <span class="keyword">if</span> x <span class="keyword">not</span> <span class="keyword">in</span> stopwords]</div><div class="line">                words = words_</div><div class="line">            fout.write(label + <span class="string">" "</span>)</div><div class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> words:</div><div class="line">                <span class="keyword">if</span> w.strip() != <span class="string">""</span>: </div><div class="line">                    fout.write(w.encode(<span class="string">"utf-8"</span>) + <span class="string">" "</span>)</div><div class="line">            fout.write(<span class="string">"\n"</span>)</div></pre></td></tr></table></figure>
<h1 id="3-Training-a-classifier"><a href="#3-Training-a-classifier" class="headerlink" title="3. Training a classifier"></a>3. Training a classifier</h1><p>预处理后,可以训练分类器了.在正文部分,笔者采用三种方法,在附录中,又提供了一种CNN做文本分类的方法.</p>
<p>正文部分的实验参考了<a href="http://city.shaform.com/blog/2015/03/27/sentiment-analysis.html" target="_blank" rel="external">这一篇文章</a>,并做了一些修改.</p>
<h2 id="3-1-rnnlm"><a href="#3-1-rnnlm" class="headerlink" title="3.1 rnnlm"></a>3.1 rnnlm</h2><p>rnnlm是一款RNN语言模型工具,可以用来做情感分类.</p>
<p>首先,训练一个positive 语言模型<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> constructs a positive language model</span></div><div class="line">rm -rf neg.model</div><div class="line">rm -rf pos.model</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash"> sed <span class="string">'1,200d'</span> means deletes line 1 to 200</span></div><div class="line">head -n 200 $&#123;training_set&#125;/pos/pos.txt.train &gt; val.txt</div><div class="line">cat $&#123;training_set&#125;/pos/pos.txt.train | sed '1,200d' &gt; train.txt</div><div class="line">./rnnlm -rnnlm pos.model -train train.txt -valid val.txt -hidden 50 -direct-order 3 -direct 200 -class 100 -debug 2 -bptt 4 -bptt-block 10 -binary</div></pre></td></tr></table></figure></p>
<p>再训练一个negative语言模型<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> constructs a negative language model</span></div><div class="line">head -n 200 $&#123;training_set&#125;/neg/neg.txt.train &gt; val.txt</div><div class="line">cat $&#123;training_set&#125;/neg/neg.txt.train | sed '1,200d' &gt; train.txt</div><div class="line">./rnnlm -rnnlm neg.model -train train.txt -valid val.txt -hidden 50 -direct-order 3 -direct 200 -class 100 -debug 2 -bptt 4 -bptt-block 10 -binary</div></pre></td></tr></table></figure></p>
<p>做一些格式化处理<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> adds id, from 0</span></div><div class="line">cat $&#123;training_set&#125;/pos/pos.txt.test $&#123;training_set&#125;/neg/neg.txt.test | nl -v0 -s' ' -w1 &gt; test.txt</div><div class="line">./rnnlm -rnnlm pos.model -test test.txt -debug 0 -nbest &gt; model_pos_score.txt</div><div class="line">./rnnlm -rnnlm neg.model -test test.txt -debug 0 -nbest &gt; model_neg_score.txt</div></pre></td></tr></table></figure></p>
<p>预测结果,并检验准确率(如下的python脚本内容不在本文所述范围以内,详情请参考<a href="https://github.com/july7cji/SentimentAnalysis" target="_blank" rel="external">我的github</a>)<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> predicts the probability of each sentence, by the model of positive and negative, <span class="keyword">then</span> outputs  result </span></div><div class="line">mkdir ../scores</div><div class="line">paste model_pos_score.txt model_neg_score.txt | awk '&#123;print $1/$2;&#125;' &gt; ../scores/RNNLM</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash"> ajusts the scope of datas, <span class="keyword">then</span> checks the accuracy</span></div><div class="line">cd ..</div><div class="line">python normalize.py --input scores/RNNLM --output scores/RNNLM --type rnnlm</div><div class="line">python evaluate.py --test_pos $&#123;training_set&#125;/pos/pos.txt.test --scores scores/RNNLM</div></pre></td></tr></table></figure></p>
<h2 id="3-2-word2vec-logistic-regression"><a href="#3-2-word2vec-logistic-regression" class="headerlink" title="3.2 word2vec + logistic regression"></a>3.2 word2vec + logistic regression</h2><p>word2vec 是我们非常熟悉的一款词向量工具,用于将词映射到一个指定维度的向量空间中,也可以用于对句子和篇章的向量化(当然,对于篇章的向量化,使用LDA也是可以的)</p>
<p>训练词向量模型:<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#</span><span class="bash"> adds line numbers, and prefix <span class="string">'@@SS-'</span>, shuffles data, trains the word2vec model</span></div><div class="line">cat $&#123;training_set&#125;/pos/pos.txt.train $&#123;training_set&#125;/neg/neg.txt.train $&#123;training_set&#125;/pos/pos.txt.test $&#123;training_set&#125;/neg/neg.txt.test | nl -v0 -s' ' -w1 | sed 's/^/@@SS-/' | shuf &gt; all.txt</div><div class="line">time ./word2vec -train all.txt -output vectors.txt -cbow 0 -size 400 -window 10 -negative 5 -hs 1 -sample 1e-3 -threads 24 -binary 0 -iter 20 -min-count 1 -sentence-vectors 1</div></pre></td></tr></table></figure></p>
<p>其中,需要将训练语料和测试语料拼接在一起,生成每个词的词向量,输出在vectors.txt文件中.</p>
<p>训练lr模型,并测试准确率<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">python3 ../transform.py --input sentence_vectors.txt --output sentence_features.txt</div><div class="line">python ../train.py --features sentence_features.txt --train_pos $&#123;training_set&#125;/pos/pos.txt.train --train_neg $&#123;training_set&#125;/neg/neg.txt.train --test_pos $&#123;training_set&#125;/pos/pos.txt.test --output_train train.txt --output_test test.txt</div><div class="line"></div><div class="line">rm model.logreg</div><div class="line">../liblinear/train -s 0 train.txt model.logreg</div><div class="line">../liblinear/predict -b 1 test.txt model.logreg out.logreg</div><div class="line"><span class="meta"></span></div><div class="line">#<span class="bash">deletes first line of out.logreg, splits by space, gets the 3rd col. saves to DOC2VEC</span></div><div class="line">sed '1d' out.logreg | cut -d' ' -f3 &gt; ../scores/DOC2VEC</div><div class="line">cd ..</div><div class="line">python normalize.py --input scores/DOC2VEC --output scores/DOC2VEC --type logreg</div><div class="line"></div><div class="line">python evaluate.py --test_pos $&#123;training_set&#125;/pos/pos.txt.test --scores scores/DOC2VEC</div></pre></td></tr></table></figure></p>
<h2 id="3-3-TF-IDF-LR"><a href="#3-3-TF-IDF-LR" class="headerlink" title="3.3 TF-IDF + LR"></a>3.3 TF-IDF + LR</h2><p>相对与word2vec, 本方案的不同之处在于,文本的向量化方式不同,本方案采用的是TF-IDF方式向量化文本.</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">cd tfidf</div><div class="line">cat $&#123;training_set&#125;/pos/pos.txt.train $&#123;training_set&#125;/neg/neg.txt.train $&#123;training_set&#125;/pos/pos.txt.test $&#123;training_set&#125;/neg/neg.txt.test &gt; all.txt</div><div class="line">python ../tfidf.py --input all.txt --output features.txt</div><div class="line">python ../train.py --features features.txt --train_pos $&#123;training_set&#125;/pos/pos.txt.train --train_neg $&#123;training_set&#125;/neg/neg.txt.train --test_pos $&#123;training_set&#125;/pos/pos.txt.test --output_train train.txt --output_test test.txt</div><div class="line"></div><div class="line">rm model.logreg</div><div class="line">../liblinear/train -s 0 train.txt model.logreg</div><div class="line">../liblinear/predict -b 1 test.txt model.logreg out.logreg</div><div class="line"></div><div class="line">sed '1d' out.logreg | cut -d' ' -f3 &gt; ../scores/TFIDF</div><div class="line">cd ..</div><div class="line">python normalize.py --input scores/TFIDF --output scores/TFIDF --type logreg</div><div class="line"></div><div class="line">python evaluate.py --test_pos $&#123;training_set&#125;/pos/pos.txt.test --scores scores/TFIDF</div></pre></td></tr></table></figure>
<h2 id="3-4-Combination"><a href="#3-4-Combination" class="headerlink" title="3.4 Combination"></a>3.4 Combination</h2><p>融合上述三种算法的结果,提高准确率<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">paste scores/RNNLM scores/DOC2VEC scores/TFIDF | awk '&#123;print ($1+$2+$3)/3;&#125;' &gt; scores/TOTAL</div><div class="line">python evaluate.py --test_pos $&#123;training_set&#125;/pos/pos.txt.test --scores scores/TOTAL</div></pre></td></tr></table></figure></p>
<h1 id="4-Using-these-models-to-predict"><a href="#4-Using-these-models-to-predict" class="headerlink" title="4. Using these models to predict"></a>4. Using these models to predict</h1><p>终于到了应用模型进行实际预测的时候了(看看表,笔者有点扛不住了,手动捂脸).与第3章中测试的不同之处在于,<br>实际应用中,我们并没有标注数据,并且,需要手工的将用户评论拆分成一个个的句子,对每个子句子进行情感分析(当然,你要是想对一个评论整体分析情感也行)</p>
<p>时间关系,笔者仅仅在这里列出几个关键的函数,其余内容请参考我的github.</p>
<p>按标点符号分割句子,由于标点符号在情感分析中非常重要,因此需要保留.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># 按pattern中的标点符号分隔句子，并且保留分隔的标点</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">my_split</span><span class="params">(s, pattern)</span>:</span></div><div class="line">    result = []</div><div class="line">    w = <span class="string">''</span></div><div class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> s:</div><div class="line">        <span class="keyword">if</span> c <span class="keyword">not</span> <span class="keyword">in</span> pattern:</div><div class="line">            w += c</div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            w += c</div><div class="line">            <span class="keyword">if</span> w <span class="keyword">in</span> pattern: <span class="comment"># 如果分割开后的仍然是一个符号，例如感叹号，说明有多个感叹号连在一起了，保留</span></div><div class="line">                w = result[<span class="number">-1</span>] + w </div><div class="line">                <span class="keyword">del</span> result[<span class="number">-1</span>]</div><div class="line">            <span class="keyword">if</span> w.strip() != <span class="string">""</span>: </div><div class="line">                result.append(w)</div><div class="line">                <span class="comment">#print w</span></div><div class="line">            w = <span class="string">''</span></div><div class="line">    <span class="keyword">if</span> w.strip() != <span class="string">''</span>: </div><div class="line">        result.append(w)</div><div class="line">    <span class="keyword">return</span> result</div></pre></td></tr></table></figure></p>
<p>同样,分割过后的句子,也要进行分词,这里不再赘述.</p>
<p>注意,在使用word2vec和TF-IDF向量化的时候,需要注意,如果待预测文本中的词,在训练集中没有,可能就会出现这些词无法向量化的问题,因此,笔者在训练时,通常会把待预测文本也添加进来,一并进行向量化的训练(<strong>不能用来训练分类器,当然,你也没法用它训练分类器,因为待预测文本都是没有标注信息的</strong>).</p>
<p><strong>最后,小小的总结一下</strong>:</p>
<ul>
<li><p>本文的前几章内容,只介绍了一种通用的情感分类方法,使用这种方法分类,效果不可能太好.还是那句话:特征工程非常重要,针对特定数据的特征挖掘程度,往往决定了你模型的上限.再牛x的模型,不做预处理,都是白搭.</p>
</li>
<li><p>神经网络这么火,很多过去需要人工来做的特征工程,现在可以用NN来做了(例如自动编码器),但是NN的效率,可能还是一个问题.总之,做特征工程,要么人痛苦,要么机器痛苦.</p>
</li>
<li><p>说到特征工程,一些同行们做情感分析时,会把一些特殊标点符号出现的次数,出现位置等等统计出来,作为输入特征进行训练,目前我还没有试过这种方法,留作以后尝试一下.</p>
</li>
<li><p>当然,如果有哪个童鞋有更好的方法,欢迎与我交流.作为小白一个,请大家轻喷.</p>
</li>
</ul>
<h1 id="Appendix-A-CNN-model-for-text-classification"><a href="#Appendix-A-CNN-model-for-text-classification" class="headerlink" title="Appendix: A CNN model for text classification"></a>Appendix: A CNN model for text classification</h1><p>卷积神经网络,想必大家已经很熟悉了.卷积神经网络通常用来做图像处理相关的工作.但是近两年,一些researchers也在用它来做NLP相关的处理,例如文本分类(包括情感分析).在短文本分析任务中，由于句子长度有限、结构紧凑、能够独立表达意思，使得CNN在处理这一类问题上成为可能.</p>
<p>本部分内容参考了<a href="http://blog.csdn.net/zbc1090549839/article/details/53055386" target="_blank" rel="external">这个链接</a>以及<a href="http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/" target="_blank" rel="external">这个链接</a>中的内容,并在其基础上做了一些修改.</p>
<p>首先,展示一下大牛Yoon Kim在论文<a href="https://arxiv.org/abs/1408.5882" target="_blank" rel="external">Convolutional Neural Networks for Sentence Classification</a>介绍的卷积神经网络:</p>
<p><img src="/images/pasted-35.png" alt="by Yoon Kim"></p>
<p>我们的目标是使用CNN对文本进行分类,既然操作的对象是文本数据,首先,就得将文本数据转换成计算机可以更容易”理解”的数据—-即,文本数据的向量化.</p>
<p>说起文本数据的向量化,第一个想到的是什么? 没错,就是著名的<strong>word 2 vectors(word embeddings)</strong>,如上图所示,我们要将文本首先变成词向量. 那么, 我们是不是还必须有一个训练好的模型? 如果我们操作的对象是英文, 那么很幸运, 你或许可以google到一个不错的word2vec模型, 然而, 有句话说的好:</p>
<div align="center"><br>汉语是博大精深的!<br></div>

<p>没错! (貌似跑题了). 更加幸运的是, 在这个模型中, 我们可以自己训练一个word2vec模型, 不过我们不需要去下载Word2vec源码, 或者自己编写一个基于TF的word2vec代码. 在训练上图的模型过程中, 它就可以自动训练出一套w2v模型来, 或者说, 在整个训练过程中, word vector是一组可以训练的参数，通过反向传播算法来Fine tune. </p>
<p>如果你随机初始化Word2vec模型参数, 那么,通过一系列的训练,你除了得到文本分类器以外,还会得到一个Word2vec模型(副产品). 当然, 如果你已经有一个训练好的w2v模型, 整个训练过程则是一个迁移训练的过程.</p>
<p>回到我们的模型中, 对于输入的一句话, 例如: “黑客军团是一部烧脑神剧”, 首先, 分词: 黑客 军团 是 一部 烧脑 神剧. 一共6个词. 假设我们的w2v模型设定词向量维度为100, 那么这6个词组成的一句话, 将会转换成相应的6行向量, 按顺序排列, 组成一个矩阵. 对于未登录词(w2v模型中不存在的词), 使用随机数初始化(或者0初始化). 在这里处理的时候,有一点需要注意, 我们得设定一个句子中词数的最大值m, 当输入的句子中词数不足m时, 我们需要补足m个词,换句话说,在这个例子中,我们要添加 m - 6 个全0向量. 我们需要保证最终的输入向量是一个 m 行 100列的 矩阵.(当然,如果词多于m,也需要裁剪移除多余的词)</p>
<p>补足的代码非常简单(x_test 是我们的原始输入文本):<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">vocab_processor = learn.preprocessing.VocabularyProcessor(m)</div><div class="line">x = numpy.array(list(vocab_processor.fit_transform(x_text)))</div></pre></td></tr></table></figure></p>
<p>接下来, 我们要开始构建CNN网络了.</p>
<h2 id="Convolution-layer"><a href="#Convolution-layer" class="headerlink" title="Convolution layer"></a>Convolution layer</h2><p>卷积层, 与inception-v3有点类似, 是由3个不同的卷积层(这么说也许不恰当)拼接(或者并联?)而成的. 更通俗的说, 是将三种不同的卷积层分别训练，然后用concat函数在深度一维联结起来.</p>
<p>3个不同的卷积层的卷积核分别为 3 * 100, 4 * 100, 5 * 100, 都采用VALID非填充方式, 步长为 1 * 1, 输出通道数为128(输入通道数为1). 在本例中,如果m值(最大词数)为100.</p>
<p>我们试着计算一下每种卷积核的参数个数:</p>
<p>$$ 3 <em> 100 </em> 1 * 128 $$</p>
<p>$$ 4 <em> 100 </em> 1 * 128 $$</p>
<p>$$ 5 <em> 100 </em> 1 * 128 $$</p>
<p>经过卷积处理过后的图像将分别为: </p>
<p>$$ (100 -3 +1) <em> (100 -100 + 1) = 98 </em> 1 $$</p>
<p>$$ (100 -4 +1) <em> (100 -100 + 1) = 97 </em> 1 $$</p>
<p>$$ (100 -5 +1) <em> (100 -100 + 1) = 96 </em> 1 $$</p>
<p>变成了一个列向量.</p>
<h2 id="Max-pool-layer"><a href="#Max-pool-layer" class="headerlink" title="Max-pool layer"></a>Max-pool layer</h2><p>为了处理三种不同的卷积层输出, 需要设计三种不同的最大池化层.这里的池化层非常简单,就是分别从上述卷积层输出的向量中,选取出最大的值.即,输出是一个 1 * 1的实数.(严格的说是一个 1 * 1 * 128的长方体, 考虑卷积核的个数的话)</p>
<h2 id="Concat"><a href="#Concat" class="headerlink" title="Concat"></a>Concat</h2><p>好了,经过池化层以后,我们可以把输出concat起来了,注意,是在深度一维进行的(类似于三种不同颜色但大小相同的乐高积木,串联成一个更长的长方体: 1 * 1 * 384)</p>
<p>这并不是一层, 只是一种trick.</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>Dropout是指在模型训练时随机让网络某些隐含层节点的权重不工作，不工作的那些节点可以暂时认为不是网络结构的一部分，但是它的权重得保留下来（只是暂时不更新而已），因为下次样本输入时它可能又得工作了，它是防止模型过拟合的一种常用的trick.</p>
<h2 id="Fully-Connected-Layer"><a href="#Fully-Connected-Layer" class="headerlink" title="Fully Connected Layer"></a>Fully Connected Layer</h2><p>全连接层, l2 正则项, 以及只有在计算损失时才需要考虑的softmax层(实际模型预测时,无需该层)</p>
<h2 id="Other-Points"><a href="#Other-Points" class="headerlink" title="Other Points"></a>Other Points</h2><p>模型介绍完了,这里再提几个要注意的点:</p>
<ul>
<li>训练模型的目的当然是使用,因此过程中务必保存好需要保存的所有变量.这其中最重要的又是那个训练好的w2v模型,一定要保存.</li>
<li>使用模型进行预测时, 给定checkpoint位置,找到meta文件(tf 1.1版本), 则无需重新构建网络结构.<a href="https://github.com/jimmy1357/cnn-text-classification-tf" target="_blank" rel="external">参考这里</a></li>
<li>既然是文本分类,本模型不限于使用在情感分析场景(二分类)或其他文本分类任务场景下. 重要的是你怎么预处理文本数据,怎么准确的标记文本数据. 不管用什么预处理方法,一定要在训练集和测试集中采用同样的方法.</li>
</ul>
<p>以上.</p>

      
      
        <div class="page-reward">
          <p><a href="javascript:void(0)" onclick="dashangToggle()" class="dashang">赏</a></p>
          <div class="hide_box"></div>
          <div class="shang_box">
            <a class="shang_close" href="javascript:void(0)" onclick="dashangToggle()">×</a>
            <div class="shang_tit">
              <p>Rewards</p>
            </div>
            <div class="shang_payimg">
              <img src="/img/alipayimg.jpg" alt="扫码支持" title="扫一扫" />
            </div>
              <div class="pay_explain">As you wish</div>
            <div class="shang_payselect">
              
                <div class="pay_item checked" data-id="alipay">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/alipay.png" alt="支付宝" /></span>
                </div>
              
              
                <div class="pay_item" data-id="wechat">
                  <span class="radiobox"></span>
                  <span class="pay_logo"><img src="/img/weixin.png" alt="微信" /></span>
                </div>
              
            </div>
            <div class="shang_info">
              <p>打开<span id="shang_pay_txt">支付宝</span>扫一扫，即可进行扫码打赏哦</p>
            </div>
          </div>
        </div>
        <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/zepto/1.2.0/zepto.min.js"></script>
        <script type="text/javascript">
          $(".pay_item").click(function(){
            $(this).addClass('checked').siblings('.pay_item').removeClass('checked');
            var dataid=$(this).attr('data-id');
            $(".shang_payimg img").attr("src","/img/"+dataid+"img.jpg");
            $("#shang_pay_txt").text(dataid=="alipay"?"支付宝":"微信");
          });
          function dashangToggle(){
            
            $(".hide_box").fadeToggle();
            $(".shang_box").fadeToggle();
          }
        </script>
      
    </div>
    
  </div>
  
    
    <div class="copyright">
        <p><span>本文标题:</span><a href="/2017/08/05/Chinese-Sentiment-Analysis/">Chinese Sentiment Analysis</a></p>
        <p><span>文章作者:</span><a href="/" title="访问 Chen 的个人博客">Chen</a></p>
        <p><span>发布时间:</span>2017年08月05日 - 18时24分</p>
        <p><span>最后更新:</span>2017年08月19日 - 22时46分</p>
        <p>
            <span>原始链接:</span><a class="post-url" href="/2017/08/05/Chinese-Sentiment-Analysis/" title="Chinese Sentiment Analysis">http://july7.me/2017/08/05/Chinese-Sentiment-Analysis/</a>
            <span class="copy-path" data-clipboard-text="原文: http://july7.me/2017/08/05/Chinese-Sentiment-Analysis/　　作者: Chen" title="点击复制文章链接"><i class="fa fa-clipboard"></i></span>
            <script src="/js/clipboard.min.js"></script>
            <script> var clipboard = new Clipboard('.copy-path'); </script>
        </p>
        <p>
            <span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" title="中国大陆 (CC BY-NC-SA 3.0 CN)" target = "_blank">"署名-非商用-相同方式共享 3.0"</a> 转载请保留原文链接及作者。
        </p>
    </div>



<nav id="article-nav">
  
    <a href="/2017/08/19/Some-Tips-of-Machine-Learning-Yearning/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Some Tips of Machine Learning Yearning
        
      </div>
    </a>
  
  
    <a href="/2017/07/18/A-CTR-Experiment/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">A CTR Prediction Experiment</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>

    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-Corpus"><span class="toc-number">1.</span> <span class="toc-text">1.Corpus</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-Data-preprocessing"><span class="toc-number">2.</span> <span class="toc-text">2. Data preprocessing</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-Training-a-classifier"><span class="toc-number">3.</span> <span class="toc-text">3. Training a classifier</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-rnnlm"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 rnnlm</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-word2vec-logistic-regression"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 word2vec + logistic regression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-TF-IDF-LR"><span class="toc-number">3.3.</span> <span class="toc-text">3.3 TF-IDF + LR</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-Combination"><span class="toc-number">3.4.</span> <span class="toc-text">3.4 Combination</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-Using-these-models-to-predict"><span class="toc-number">4.</span> <span class="toc-text">4. Using these models to predict</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Appendix-A-CNN-model-for-text-classification"><span class="toc-number">5.</span> <span class="toc-text">Appendix: A CNN model for text classification</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Convolution-layer"><span class="toc-number">5.1.</span> <span class="toc-text">Convolution layer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Max-pool-layer"><span class="toc-number">5.2.</span> <span class="toc-text">Max-pool layer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Concat"><span class="toc-number">5.3.</span> <span class="toc-text">Concat</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dropout"><span class="toc-number">5.4.</span> <span class="toc-text">Dropout</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fully-Connected-Layer"><span class="toc-number">5.5.</span> <span class="toc-text">Fully Connected Layer</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Other-Points"><span class="toc-number">5.6.</span> <span class="toc-text">Other Points</span></a></li></ol></li></ol>
</div>
<input type="button" id="tocButton" value="隐藏目录"  title="点击按钮隐藏或者显示文章目录">

<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script>
    var valueHide = "隐藏目录";
    var valueShow = "显示目录";

    if ($(".left-col").is(":hidden")) {
        $("#tocButton").attr("value", valueShow);
    }
    $("#tocButton").click(function() {
        if ($("#toc").is(":hidden")) {
            $("#tocButton").attr("value", valueHide);
            $("#toc").slideDown(320);
        }
        else {
            $("#tocButton").attr("value", valueShow);
            $("#toc").slideUp(350);
        }
    })
    if ($(".toc").length < 1) {
        $("#toc, #tocButton").hide();
    }
</script>





<div class="bdsharebuttonbox">
	<a href="#" class="fx fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
	<a href="#" class="fx fa-weixin bds_weixin" data-cmd="weixin" title="分享到微信"></a>
	<a href="#" class="fx fa-qq bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>
	<a href="#" class="fx fa-facebook-official bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
	<a href="#" class="fx fa-twitter bds_twi" data-cmd="twi" title="分享到Twitter"></a>
	<a href="#" class="fx fa-linkedin bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
	<a href="#" class="fx fa-files-o bds_copy" data-cmd="copy" title="分享到复制网址"></a>
</div>
<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>




    
        <section id="comments">
  <div id="disqus_thread"></div>
    <script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'july7-me'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>
    



    <div class="scroll" id="post-nav-button">
        
            <a href="/2017/08/19/Some-Tips-of-Machine-Learning-Yearning/" title="上一篇: Some Tips of Machine Learning Yearning">
                <i class="fa fa-angle-left"></i>
            </a>
        
        <a title="文章列表"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>
        
            <a href="/2017/07/18/A-CTR-Experiment/" title="下一篇: A CTR Prediction Experiment">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>
    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/08/19/Some-Tips-of-Machine-Learning-Yearning/">Some Tips of Machine Learning Yearning</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/05/Chinese-Sentiment-Analysis/">Chinese Sentiment Analysis</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/18/A-CTR-Experiment/">A CTR Prediction Experiment</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/29/Feature-Engineering/">Feature Engineering</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/17/hello-world/">Hello World</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/17/Hexo-Admin-插件错误小结/">Errors when using Hexo Admin </a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/16/Just-for-fun/">Just for fun</a></li></ul>
    <script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
    <script>
        $(".post-list").addClass("toc-article");
        $(".post-list-item a").attr("target","_blank");
        $("#post-nav-button > a:nth-child(2)").click(function() {
            $(".fa-bars, .fa-times").toggle();
            $(".post-list").toggle(300);
            if ($(".toc").length > 0) {
                $("#toc, #tocButton").toggle(200, function() {
                    if ($(".switch-area").is(":visible")) {
                        $("#tocButton").attr("value", valueHide);
                        }
                    })
            }
            else {
            }
        })
    </script>



    <script>
        
    </script>

</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2017 Chen
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/luuman/hexo-theme-spfk" target="_blank">spfk</a> by luuman
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_pv" style='display:none'>
                        <span id="site-visit" >一笑回眸: 
                            <span id="busuanzi_value_site_uv"></span>
                        </span>
                    </span>
                
                
                    <span>, </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit">擦肩而过: 
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>

    </div>
    <script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>
<script src="/js/main.js"></script>

    <script>
        $(document).ready(function() {
            var backgroundnum = 24;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>





<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(

            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


  </div>
</body>
</html>